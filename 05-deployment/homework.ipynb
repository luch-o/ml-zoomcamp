{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 5: Deployment Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "- Install Pipenv\n",
    "- Whats the version of pipenv you installed?\n",
    "\n",
    "> use `--version` to find out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output obtained:\n",
    "\n",
    "```bash\n",
    "$ pip install pipenv\n",
    "...\n",
    "$ pipenv --version\n",
    "pipenv, version 2022.10.12\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "- Use pipenv to install Scikit-learn version 1.0.2\n",
    "- What's the firts hash for scikit-learn you get in Pipfile.lock?\n",
    "\n",
    "> **Note**: you should create an empty folder for homework and do it there"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install scikit-learn with\n",
    "```bash\n",
    "$ pipenv install scikit-learn==1.0.2\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sha256:08ef968f6b72033c16c479c966bf37ccd49b06ea91b765e1cc27afefe723920b\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"Pipfile.lock\", \"r\") as file:\n",
    "    lock = json.load(file)\n",
    "\n",
    "print(lock[\"default\"][\"scikit-learn\"][\"hashes\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n",
    "\n",
    "We've prepared a dictionary vectorizer and a model.\n",
    "\n",
    "They were trained (roughly) using this code:\n",
    "\n",
    "```python\n",
    "features = ['reports', 'share', 'expenditure', 'owner']\n",
    "dicts = df[features].to_dict(orient='records')\n",
    "\n",
    "dv = DictVectorizer(sparse=False)\n",
    "X = dv.fit_transform(dicts)\n",
    "\n",
    "model = LogisticRegression(solver='liblinear').fit(X, y)\n",
    "```\n",
    "\n",
    "> **Note**: You don't need to train the model. This code is just for your reference.\n",
    "\n",
    "And then saved with Pickle. Download them:\n",
    "\n",
    "* [DictVectorizer](https://github.com/alexeygrigorev/mlbookcamp-code/blob/master/course-zoomcamp/cohorts/2022/05-deployment/homework/dv.bin?raw=true)\n",
    "* [LogisticRegression](https://github.com/alexeygrigorev/mlbookcamp-code/blob/master/course-zoomcamp/cohorts/2022/05-deployment/homework/model1.bin?raw=true)\n",
    "\n",
    "With `wget`:\n",
    "\n",
    "```bash\n",
    "PREFIX=https://raw.githubusercontent.com/alexeygrigorev/mlbookcamp-code/master/course-zoomcamp/cohorts/2022/05-deployment/homework\n",
    "wget $PREFIX/model1.bin\n",
    "wget $PREFIX/dv.bin\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "Let's use these models!\n",
    "\n",
    "* Write a script for loading these models with pickle\n",
    "* Score this client:\n",
    "\n",
    "```json\n",
    "{\"reports\": 0, \"share\": 0.001694, \"expenditure\": 0.12, \"owner\": \"yes\"}\n",
    "```\n",
    "\n",
    "What's the probability that this client will get a credit card? \n",
    "\n",
    "* 0.162\n",
    "* 0.391\n",
    "* 0.601\n",
    "* 0.993\n",
    "\n",
    "If you're getting errors when unpickling the files, check their checksum:\n",
    "\n",
    "```bash\n",
    "$ md5sum model1.bin dv.bin\n",
    "3f57f3ebfdf57a9e1368dcd0f28a4a14  model1.bin\n",
    "6b7cded86a52af7e81859647fa3a5c2e  dv.bin\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LogisticRegression(solver='liblinear'), DictVectorizer(sparse=False))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"model1.bin\", \"rb\") as model_fh, open(\"dv.bin\", \"rb\") as dv_bin:\n",
    "    model = pickle.load(model_fh)\n",
    "    dv = pickle.load(dv_bin)\n",
    "\n",
    "model, dv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred=0.162\n"
     ]
    }
   ],
   "source": [
    "sample = {\"reports\": 0, \"share\": 0.001694, \"expenditure\": 0.12, \"owner\": \"yes\"}\n",
    "\n",
    "x = dv.transform(sample)\n",
    "y_pred = model.predict_proba(x)[0][1]\n",
    "\n",
    "print(f\"{y_pred=:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "Now let's serve this model as a web service\n",
    "\n",
    "* Install Flask and gunicorn (or waitress, if you're on Windows) (I used FastAPI and uvicorn)\n",
    "* Write Flask code for serving the model\n",
    "* Now score this client using `requests`:\n",
    "\n",
    "```python\n",
    "url = \"YOUR_URL\"\n",
    "client = {\"reports\": 0, \"share\": 0.245, \"expenditure\": 3.438, \"owner\": \"yes\"}\n",
    "requests.post(url, json=client).json()\n",
    "```\n",
    "\n",
    "What's the probability that this client will get a credit card?\n",
    "\n",
    "* 0.274\n",
    "* 0.484\n",
    "* 0.698\n",
    "* 0.928"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First install FastAPI and uvicorn\n",
    "\n",
    "```bash\n",
    "$ pipenv install fastapi uvicorn\n",
    "```\n",
    "\n",
    "Then write the code to serve the model as a web service. Here we use pydantic to validate the input of the model, and therefore we need to use the `.dict()` method to transform it using the `DictVectorizer`. The code is in the `service.py` file\n",
    "\n",
    "```python\n",
    "import pickle\n",
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Sample(BaseModel):\n",
    "    reports: int\n",
    "    share: float\n",
    "    expenditure: float\n",
    "    owner: str\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "with open(\"model1.bin\", \"rb\") as model_fh, open(\"dv.bin\", \"rb\") as dv_bin:\n",
    "    model = pickle.load(model_fh)\n",
    "    dv = pickle.load(dv_bin)\n",
    "\n",
    "@app.post(\"/predict\")\n",
    "def predict(sample: Sample):\n",
    "    x = dv.transform(sample)\n",
    "    y = model.predict_proba(x)[0][1]\n",
    "\n",
    "    return {\n",
    "        \"probability\": y\n",
    "    }\n",
    "\n",
    "```\n",
    "\n",
    "Start the local server to test the service\n",
    "\n",
    "```bash\n",
    "$ uvicorn service:app \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'probability': 0.9282218018527452}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"http://127.0.0.1:8000/predict\"\n",
    "client = {\"reports\": 0, \"share\": 0.245, \"expenditure\": 3.438, \"owner\": \"yes\"}\n",
    "requests.post(url, json=client).json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Docker\n",
    "\n",
    "Install [Docker](https://github.com/alexeygrigorev/mlbookcamp-code/blob/master/course-zoomcamp/05-deployment/06-docker.md). We will use it for the next two questions.\n",
    "\n",
    "For these questions, we prepared a base image: `svizor/zoomcamp-model:3.9.12-slim`. \n",
    "You'll need to use it (see Question 5 for an example).\n",
    "\n",
    "This image is based on `python:3.9.12-slim` and has a logistic regression model \n",
    "(a different one) as well a dictionary vectorizer inside. \n",
    "\n",
    "This is how the Dockerfile for this image looks like:\n",
    "\n",
    "```docker \n",
    "FROM python:3.9.12-slim\n",
    "WORKDIR /app\n",
    "COPY [\"model2.bin\", \"dv.bin\", \"./\"]\n",
    "```\n",
    "\n",
    "We already built it and then pushed it to [`svizor/zoomcamp-model:3.9.12-slim`](https://hub.docker.com/r/svizor/zoomcamp-model).\n",
    "\n",
    "> **Note**: You don't need to build this docker image, it's just for your reference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('05-deployment-H6F8z2rp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7024eab4779f9a6d99ca1a6d20eb79df8b0b4491e3650f6a6838b2fb9033ecec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
